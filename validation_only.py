# -*- coding: utf-8 -*-
"""validation_only.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-6s0ycgPYGD8nLELLQjoLlqaW_kl0Q-

# Validación de Modelos Entrenados - Detección de Cáncer Colorrectal

Este notebook contiene únicamente el código de validación para los modelos ya entrenados.
"""

# Importación de librerías necesarias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
import cv2
import os
from time import time
import math
from tensorflow.keras.utils import Sequence
import warnings
warnings.filterwarnings('ignore')

print("✅ Librerías importadas correctamente")
print(f"TensorFlow version: {tf.__version__}")

# Configuración general
batch_size = 64
img_size = (224, 224)
class_names = ['ADI', 'BACK', 'DEB', 'LYM', 'MUC', 'MUS', 'NORM', 'STR', 'TUM']
num_classes = len(class_names)

# Rutas de modelos entrenados
MODEL_PATHS = {
    'CNN_Simple': 'models/cnn_simple_model.h5',
    'ResNet50': 'models/resnet50.keras',
    'MobileNetV2': 'models/mobilenetv2_base_only.h5',
    'HybridAttention': 'models/Fast_HybridAttention_final.h5',
    'HybridAutoencoder': 'models/Fast_HybridAutoencoder_final.h5'
}

print("📋 Configuración establecida:")
print(f"   - Tamaño de imagen: {img_size}")
print(f"   - Número de clases: {num_classes}")
print(f"   - Clases: {class_names}")

# Generador de datos para validación (sin data augmentation)
class ValidationDataGenerator(Sequence):
    def __init__(self, data_dir, batch_size=32, img_size=(224, 224), sample_size=1.0):
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.img_size = img_size
        self.sample_size = sample_size

        # Obtener clases del directorio
        self.class_names = sorted(os.listdir(data_dir))

        # Listar todas las imágenes
        self.image_paths = []
        self.labels = []

        for class_idx, class_name in enumerate(self.class_names):
            class_path = os.path.join(data_dir, class_name)
            if os.path.isdir(class_path):
                img_files = [f for f in os.listdir(class_path)
                           if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))]

                # Muestrear si es necesario
                sample_count = int(len(img_files) * self.sample_size)
                img_files = img_files[:sample_count]

                for img_name in img_files:
                    self.image_paths.append(os.path.join(class_path, img_name))
                    self.labels.append(class_idx)

        self.indices = np.arange(len(self.image_paths))
        print(f"📊 Dataset cargado: {len(self.image_paths)} imágenes")

    def __len__(self):
        return math.ceil(len(self.image_paths) / self.batch_size)

    def __getitem__(self, index):
        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]
        X = []
        y = []

        for i in batch_indices:
            try:
                # Cargar imagen
                img = cv2.imread(self.image_paths[i])
                if img is None:
                    continue

                # Convertir BGR a RGB
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                # Redimensionar
                img = cv2.resize(img, self.img_size)

                # Normalizar
                img = img / 255.0

                X.append(img)
                y.append(self.labels[i])
            except Exception as e:
                print(f"Error cargando imagen {self.image_paths[i]}: {e}")
                continue

        return np.array(X), np.array(y)
    
    def get_batch_for_model(self, index, target_size, apply_clahe=False):
        """Obtiene un batch redimensionado para un modelo específico"""
        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]
        X = []
        y = []

        for i in batch_indices:
            try:
                # Cargar imagen
                img = cv2.imread(self.image_paths[i])
                if img is None:
                    continue

                # Convertir BGR a RGB
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                # Aplicar CLAHE si se solicita
                if apply_clahe:
                    img = self.apply_clahe_preprocessing(img)

                # Redimensionar al tamaño específico del modelo
                img = cv2.resize(img, target_size)

                # Normalizar
                img = img / 255.0

                X.append(img)
                y.append(self.labels[i])
            except Exception as e:
                print(f"Error cargando imagen {self.image_paths[i]}: {e}")
                continue

        return np.array(X), np.array(y)
    
    def __getitem__(self, index, apply_clahe=False):
        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]
        X = []
        y = []

        for i in batch_indices:
            try:
                # Cargar imagen
                img = cv2.imread(self.image_paths[i])
                if img is None:
                    continue

                # Convertir BGR a RGB
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                # Aplicar CLAHE si se solicita
                if apply_clahe:
                    img = self.apply_clahe_preprocessing(img)

                # Redimensionar
                img = cv2.resize(img, self.img_size)

                # Normalizar
                img = img / 255.0

                X.append(img)
                y.append(self.labels[i])
            except Exception as e:
                print(f"Error cargando imagen {self.image_paths[i]}: {e}")
                continue

        return np.array(X), np.array(y)
    
    def apply_clahe_preprocessing(self, img):
        """Aplica preprocesamiento CLAHE a la imagen"""
        # Convertir a LAB para aplicar CLAHE solo al canal L
        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
        
        # Crear objeto CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        
        # Aplicar CLAHE al canal L
        lab[:, :, 0] = clahe.apply(lab[:, :, 0])
        
        # Convertir de vuelta a RGB
        img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        
        return img_clahe

    def get_all_labels(self):
        """Obtiene todas las etiquetas verdaderas"""
        return np.array(self.labels)

    def get_class_distribution(self):
        """Devuelve la distribución de clases"""
        unique, counts = np.unique(self.labels, return_counts=True)
        return dict(zip(unique, counts))

print("✅ Generador de validación definido")

# Cargar datos de validación
# Ajusta esta ruta según tu estructura de datos
DATA_DIR = 'CRC-VAL-HE-7K'  # Buscar en el directorio actual primero

# Intentar diferentes rutas posibles
possible_paths = [
    'CRC-VAL-HE-7K',
    '../CRC-VAL-HE-7K', 
    '../../CRC-VAL-HE-7K',
    '../../../CRC-VAL-HE-7K',
    'PRUEBAS',
    '../PRUEBAS',
    'data/CRC-VAL-HE-7K',
    'dataset/CRC-VAL-HE-7K'
]

DATA_DIR = None
for path in possible_paths:
    if os.path.exists(path):
        DATA_DIR = path
        print(f"✅ Encontrado directorio de datos en: {path}")
        break

if DATA_DIR and os.path.exists(DATA_DIR):
    val_generator = ValidationDataGenerator(
        data_dir=DATA_DIR,
        batch_size=batch_size,
        img_size=img_size,
        sample_size=1  # Usar 10% de los datos para validación rápida
    )

    print(f"📈 Distribución de clases en validación:")
    distribution = val_generator.get_class_distribution()
    for class_idx, count in distribution.items():
        print(f"   {val_generator.class_names[class_idx]}: {count} imágenes")
else:
    print(f"❌ No se encontró ningún directorio de datos válido")
    print("📁 Directorios disponibles en el directorio actual:")
    try:
        for item in os.listdir('.'):
            if os.path.isdir(item):
                print(f"   - {item}/")
                # Verificar si contiene subdirectorios que podrían ser clases
                try:
                    subdirs = [d for d in os.listdir(item) if os.path.isdir(os.path.join(item, d))]
                    if len(subdirs) > 0:
                        print(f"     Subdirectorios: {subdirs[:5]}{'...' if len(subdirs) > 5 else ''}")
                except:
                    pass
    except Exception as e:
        print(f"   Error listando directorios: {e}")
    
    print("\n💡 Sugerencias:")
    print("   1. Asegúrate de que el directorio de datos esté en la ubicación correcta")
    print("   2. El directorio debe contener subdirectorios con nombres de clases")
    print("   3. Cada subdirectorio debe contener imágenes (.png, .jpg, .jpeg, .tif, .tiff)")
    print("   4. Estructura esperada:")
    print("      CRC-VAL-HE-7K/")
    print("      ├── ADI/")
    print("      ├── BACK/") 
    print("      ├── DEB/")
    print("      └── ...")

# Función para cargar modelos
def load_model_safe(model_path, model_name):
    """Carga un modelo de forma segura"""
    try:
        if os.path.isdir(model_path):  # SavedModel format
            # Para Keras 3, usar TFSMLayer para modelos SavedModel
            print(f"⚠️ Cargando {model_name} como TFSMLayer (SavedModel format)")
            
            # Crear un wrapper para el modelo SavedModel
            class SavedModelWrapper(tf.keras.Model):
                def __init__(self, saved_model_path):
                    super().__init__()
                    self.tfsm_layer = tf.keras.layers.TFSMLayer(
                        saved_model_path, 
                        call_endpoint='serving_default'
                    )
                
                def call(self, inputs):
                    # El output del TFSMLayer puede tener diferentes formatos
                    result = self.tfsm_layer(inputs)
                    if isinstance(result, dict):
                        # Si es un diccionario, tomar el primer valor
                        return list(result.values())[0]
                    return result
                
                def count_params(self):
                    return sum([tf.size(var).numpy() for var in self.trainable_variables])
            
            model = SavedModelWrapper(model_path)
            
        else:  # .h5 format
            model = tf.keras.models.load_model(model_path)

        print(f"✅ {model_name} cargado correctamente")
        try:
            params = model.count_params()
            print(f"   📊 Parámetros: {params:,}")
        except:
            print(f"   📊 Parámetros: No disponible para este formato")
        return model
    except Exception as e:
        print(f"❌ Error cargando {model_name}: {str(e)}")
        return None

# Cargar todos los modelos disponibles
loaded_models = {}

for model_name, model_path in MODEL_PATHS.items():
    if os.path.exists(model_path):
        model = load_model_safe(model_path, model_name)
        if model is not None:
            loaded_models[model_name] = model
    else:
        print(f"⚠️ No se encontró el modelo {model_name} en {model_path}")

print(f"\n📋 Modelos cargados exitosamente: {len(loaded_models)}")
for name in loaded_models.keys():
    print(f"   ✅ {name}")

# Función para validar un modelo
def validate_model(model, model_name, val_generator, apply_clahe=False):
    """Valida un modelo y devuelve métricas detalladas"""
    clahe_suffix = " (con CLAHE)" if apply_clahe else ""
    print(f"\n{'='*50}")
    print(f"🔍 Validando modelo: {model_name}{clahe_suffix}")
    print(f"{'='*50}")

    start_time = time()

    # Determinar el tamaño de entrada requerido por el modelo
    try:
        input_shape = model.input_shape
        if isinstance(input_shape, list):
            input_shape = input_shape[0]  # Tomar la primera entrada si hay múltiples
        
        expected_height = input_shape[1] if input_shape[1] is not None else 224
        expected_width = input_shape[2] if input_shape[2] is not None else 224
        model_input_size = (expected_width, expected_height)
        
        print(f"📐 Tamaño de entrada del modelo: {model_input_size}")
        if apply_clahe:
            print(f"🔧 Aplicando preprocesamiento CLAHE")
    except Exception as e:
        print(f"⚠️ No se pudo determinar el tamaño de entrada: {e}")
        print(f"📐 Usando tamaño por defecto: (224, 224)")
        model_input_size = (224, 224)

    # Obtener predicciones
    print("📊 Generando predicciones...")
    predictions = []
    true_labels = []

    for i in range(len(val_generator)):
        try:
            # Obtener batch con el tamaño correcto para este modelo
            if model_input_size != (224, 224):
                batch_x, batch_y = val_generator.get_batch_for_model(i, model_input_size, apply_clahe)
            else:
                # Para el método __getitem__ necesitamos una implementación especial
                if apply_clahe:
                    batch_x, batch_y = get_batch_with_clahe(val_generator, i)
                else:
                    batch_x, batch_y = val_generator[i]
            
            if len(batch_x) > 0:
                batch_pred = model.predict(batch_x, verbose=0)
                
                # Manejar diferentes formatos de salida
                if isinstance(batch_pred, dict):
                    # Si es un diccionario, tomar el primer valor
                    batch_pred = list(batch_pred.values())[0]
                
                predictions.extend(batch_pred)
                true_labels.extend(batch_y)
        except Exception as e:
            print(f"⚠️ Error en batch {i}: {e}")
            continue

    if len(predictions) == 0:
        print("❌ No se pudieron obtener predicciones")
        return None

    predictions = np.array(predictions)
    true_labels = np.array(true_labels)
    predicted_labels = np.argmax(predictions, axis=1)

    # Calcular métricas
    accuracy = accuracy_score(true_labels, predicted_labels)
    precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=0)
    recall = recall_score(true_labels, predicted_labels, average='weighted', zero_division=0)
    f1 = f1_score(true_labels, predicted_labels, average='weighted', zero_division=0)

    # Top-3 accuracy
    if predictions.shape[1] >= 3:
        top3_predictions = tf.nn.top_k(predictions, k=3).indices.numpy()
        top3_accuracy = np.mean([true_labels[i] in top3_predictions[i] for i in range(len(true_labels))])
    else:
        top3_accuracy = accuracy  # Si hay menos de 3 clases, usar accuracy normal

    validation_time = time() - start_time

    # Mostrar resultados
    print(f"\n📊 RESULTADOS DE VALIDACIÓN:")
    print(f"   🎯 Precisión (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   🎯 Top-3 Accuracy: {top3_accuracy:.4f} ({top3_accuracy*100:.2f}%)")
    print(f"   📈 Precisión (Precision): {precision:.4f}")
    print(f"   📈 Sensibilidad (Recall): {recall:.4f}")
    print(f"   📈 F1-Score: {f1:.4f}")
    print(f"   ⏱️ Tiempo de validación: {validation_time:.2f} segundos")
    print(f"   📊 Muestras evaluadas: {len(true_labels)}")

    # Reporte detallado por clase
    print(f"\n📋 REPORTE DETALLADO POR CLASE:")
    try:
        report = classification_report(
            true_labels,
            predicted_labels,
            target_names=class_names,
            digits=4,
            zero_division=0
        )
        print(report)
    except Exception as e:
        print(f"⚠️ Error generando reporte detallado: {e}")
        report = "No disponible"

    # Matriz de confusión
    cm = confusion_matrix(true_labels, predicted_labels)
    
    # Mostrar matriz de confusión en terminal (números absolutos)
    print(f"\n📊 MATRIZ DE CONFUSIÓN (Números Absolutos):")
    print("=" * 80)
    
    # Encabezados
    header = "Verdadero\\Predicho" + "".join(f"{name:>8}" for name in class_names) + "  Total"
    print(header)
    print("-" * len(header))
    
    # Filas de la matriz con números absolutos
    for i, true_class in enumerate(class_names):
        row = f"{true_class:<15}"
        for j in range(len(class_names)):
            row += f"{cm[i,j]:>8d}"
        row += f"{cm[i].sum():>7d}"
        print(row)
    
    # Fila de totales
    total_row = "Total" + " " * 10
    for j in range(len(class_names)):
        total_row += f"{cm[:,j].sum():>8d}"
    total_row += f"{cm.sum():>7d}"
    print("-" * len(header))
    print(total_row)
    print("=" * 80)
    
    # Matriz normalizada por clase (porcentajes)
    print(f"\n📊 MATRIZ DE CONFUSIÓN (Porcentajes por Clase Real):")
    print("=" * 80)
    
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    # Encabezados para porcentajes
    header_pct = "Verdadero\\Predicho" + "".join(f"{name:>8}" for name in class_names) + "  Total"
    print(header_pct)
    print("-" * len(header_pct))
    
    # Filas de la matriz con porcentajes
    for i, true_class in enumerate(class_names):
        row = f"{true_class:<15}"
        for j in range(len(class_names)):
            percentage = cm_normalized[i,j] * 100
            row += f"{percentage:>7.1f}%"
        row += f" 100.0%"
        print(row)
    
    print("=" * 80)
    
    # Estadísticas adicionales por clase
    print(f"\n📈 ESTADÍSTICAS POR CLASE:")
    for i, class_name in enumerate(class_names):
        if cm[i].sum() > 0:
            class_accuracy = cm[i,i] / cm[i].sum()
            correct = cm[i,i]
            total = cm[i].sum()
            print(f"   {class_name}: {correct}/{total} = {class_accuracy:.4f} ({class_accuracy*100:.2f}%)")
        else:
            print(f"   {class_name}: Sin muestras")

    return {
        'model_name': model_name + clahe_suffix,
        'accuracy': accuracy,
        'top3_accuracy': top3_accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'validation_time': validation_time,
        'samples_evaluated': len(true_labels),
        'confusion_matrix': cm,
        'classification_report': report,
        'predictions': predictions,
        'true_labels': true_labels,
        'predicted_labels': predicted_labels
    }

# Función auxiliar para obtener batch con CLAHE
def get_batch_with_clahe(val_generator, index):
    """Obtiene un batch aplicando CLAHE"""
    batch_indices = val_generator.indices[index*val_generator.batch_size:(index+1)*val_generator.batch_size]
    X = []
    y = []

    for i in batch_indices:
        try:
            # Cargar imagen
            img = cv2.imread(val_generator.image_paths[i])
            if img is None:
                continue

            # Convertir BGR a RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            # Aplicar CLAHE
            img = val_generator.apply_clahe_preprocessing(img)

            # Redimensionar
            img = cv2.resize(img, val_generator.img_size)

            # Normalizar
            img = img / 255.0

            X.append(img)
            y.append(val_generator.labels[i])
        except Exception as e:
            print(f"Error cargando imagen {val_generator.image_paths[i]}: {e}")
            continue

    return np.array(X), np.array(y)

print("✅ Función de validación definida")

# Función para generar matriz de confusión
def plot_confusion_matrix(cm, model_name, class_names):
    """Genera una matriz de confusión visualizada"""
    plt.figure(figsize=(10, 8))

    # Normalizar la matriz de confusión
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    sns.heatmap(cm_normalized,
                annot=True,
                fmt='.3f',
                cmap='Blues',
                xticklabels=class_names,
                yticklabels=class_names,
                cbar_kws={'label': 'Proporción normalizada'})

    plt.title(f'Matriz de Confusión Normalizada - {model_name}',
              fontsize=14, fontweight='bold')
    plt.xlabel('Predicción', fontsize=12)
    plt.ylabel('Verdadero', fontsize=12)
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()

    # Guardar la imagen
    os.makedirs('reports', exist_ok=True)
    plt.savefig(f'reports/{model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()

    return cm_normalized

print("✅ Función para matriz de confusión definida")

# VALIDACIÓN DE TODOS LOS MODELOS
print("🚀 INICIANDO VALIDACIÓN DE TODOS LOS MODELOS")
print("="*60)

validation_results = {}

if 'val_generator' in locals() and len(loaded_models) > 0:
    # Validación normal de todos los modelos
    for model_name, model in loaded_models.items():
        try:
            print(f"\n🔧 Preparando validación para {model_name}...")
            
            # Validar modelo sin CLAHE
            result = validate_model(model, model_name, val_generator, apply_clahe=False)
            
            if result is not None:
                validation_results[model_name] = result
                
                # Generar matriz de confusión
                plot_confusion_matrix(result['confusion_matrix'], model_name, class_names)
            else:
                print(f"⚠️ No se pudo validar {model_name} - saltando...")

        except Exception as e:
            print(f"❌ Error validando {model_name}: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    print(f"\n✅ Validación normal completada. Modelos validados exitosamente: {len(validation_results)}")
    
    # Pregunta opcional para validación con CLAHE
    print("\n" + "="*80)
    print("🔬 VALIDACIÓN OPCIONAL CON PREPROCESAMIENTO CLAHE")
    print("="*80)
    print("CLAHE (Contrast Limited Adaptive Histogram Equalization) puede mejorar")
    print("el contraste y la visibilidad de características en imágenes médicas.")
    print()
    
    # Verificar qué modelos están disponibles para CLAHE
    clahe_models = {}
    if 'ResNet50' in loaded_models:
        clahe_models['ResNet50'] = loaded_models['ResNet50']
    
    if clahe_models:
        print(f"Modelos disponibles para validación con CLAHE: {list(clahe_models.keys())}")
        
        while True:
            answer = input("\n¿Desea validar ResNet50 y MobileNetV2 con preprocesamiento CLAHE? (s/n): ").lower().strip()
            if answer in ['s', 'si', 'sí', 'y', 'yes']:
                print("\n🔬 Iniciando validación con CLAHE...")
                
                for model_name, model in clahe_models.items():
                    try:
                        print(f"\n🔧 Preparando validación CLAHE para {model_name}...")
                        
                        # Validar modelo con CLAHE
                        result_clahe = validate_model(model, model_name, val_generator, apply_clahe=True)
                        
                        if result_clahe is not None:
                            validation_results[model_name + " (con CLAHE)"] = result_clahe
                            
                            # Generar matriz de confusión
                            plot_confusion_matrix(result_clahe['confusion_matrix'], 
                                                model_name + " (con CLAHE)", class_names)
                        else:
                            print(f"⚠️ No se pudo validar {model_name} con CLAHE - saltando...")

                    except Exception as e:
                        print(f"❌ Error validando {model_name} con CLAHE: {str(e)}")
                        import traceback
                        traceback.print_exc()
                        continue
                
                print(f"\n✅ Validación con CLAHE completada.")
                break
                
            elif answer in ['n', 'no']:
                print("⚠️ Saltando validación con CLAHE.")
                break
            else:
                print("⚠️ Por favor responda 's' para sí o 'n' para no.")
    else:
        print("⚠️ No hay modelos ResNet50 o MobileNetV2 disponibles para validación con CLAHE.")
    
    print(f"\n✅ Validación total completada. Modelos validados: {len(validation_results)}")
else:
    print("❌ No hay modelos cargados o datos de validación disponibles")
    if 'val_generator' not in locals():
        print("   - No se pudo cargar el generador de datos de validación")
    if len(loaded_models) == 0:
        print("   - No se cargaron modelos correctamente")

# RESUMEN COMPARATIVO DE TODOS LOS MODELOS
if validation_results:
    print("\n" + "="*80)
    print("🏆 RESUMEN COMPARATIVO DE VALIDACIÓN")
    print("="*80)

    # Crear DataFrame con resultados
    summary_data = []
    for model_name, result in validation_results.items():
        summary_data.append({
            'Modelo': model_name,
            'Accuracy': f"{result['accuracy']:.4f} ({result['accuracy']*100:.2f}%)",
            'Top-3 Acc': f"{result['top3_accuracy']:.4f} ({result['top3_accuracy']*100:.2f}%)",
            'Precision': f"{result['precision']:.4f}",
            'Recall': f"{result['recall']:.4f}",
            'F1-Score': f"{result['f1_score']:.4f}",
            'Tiempo (s)': f"{result['validation_time']:.2f}",
            'Muestras': result['samples_evaluated']
        })

    df_summary = pd.DataFrame(summary_data)

    print("\n📊 TABLA COMPARATIVA:")
    print(df_summary.to_string(index=False))

    # Encontrar el mejor modelo
    best_model = max(validation_results.items(), key=lambda x: x[1]['accuracy'])
    best_name, best_result = best_model

    print(f"\n🥇 MEJOR MODELO: {best_name}")
    print(f"   🎯 Mejor Accuracy: {best_result['accuracy']:.4f} ({best_result['accuracy']*100:.2f}%)")
    print(f"   🎯 Top-3 Accuracy: {best_result['top3_accuracy']:.4f} ({best_result['top3_accuracy']*100:.2f}%)")
    print(f"   📈 F1-Score: {best_result['f1_score']:.4f}")

    # Guardar resultados
    df_summary.to_csv('reports/validation_summary.csv', index=False)
    print(f"\n💾 Resultados guardados en: reports/validation_summary.csv")

    # Gráfico comparativo
    plt.figure(figsize=(12, 8))

    models = list(validation_results.keys())
    accuracies = [validation_results[model]['accuracy'] for model in models]
    f1_scores = [validation_results[model]['f1_score'] for model in models]

    x = np.arange(len(models))
    width = 0.35

    plt.subplot(1, 2, 1)
    bars1 = plt.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')
    bars2 = plt.bar(x + width/2, f1_scores, width, label='F1-Score', alpha=0.8, color='lightcoral')

    plt.xlabel('Modelos')
    plt.ylabel('Score')
    plt.title('Comparación de Modelos - Accuracy vs F1-Score')
    plt.xticks(x, models, rotation=45)
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Añadir valores en las barras
    for bar in bars1:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8)

    for bar in bars2:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8)

    # Top-3 Accuracy
    plt.subplot(1, 2, 2)
    top3_accs = [validation_results[model]['top3_accuracy'] for model in models]
    bars3 = plt.bar(models, top3_accs, alpha=0.8, color='lightgreen')

    plt.xlabel('Modelos')
    plt.ylabel('Top-3 Accuracy')
    plt.title('Top-3 Accuracy por Modelo')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)

    for bar in bars3:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8)

    plt.tight_layout()
    plt.savefig('reports/models_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

else:
    print("❌ No hay resultados de validación para mostrar")

